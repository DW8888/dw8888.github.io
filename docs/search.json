[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Data Engineer | Data Scientist\nNew York, NY\nðŸ“§ darwhin88@gmail.com\nðŸ”— https://linkedin.com/in/darwhin-gomez\nðŸ’» https://github.com/dw8888\n\n\n\nData engineer and data scientist with a Master of Science in Data Science and Machine Learning (GPA 4.0) and hands-on experience designing data pipelines, analytics workflows, and ML-enabled systems. Former AWS Solutions Architect Intern, where I built scalable, cloud-based analytics and NLP pipelines processing millions of records. Strong foundation in Python, SQL, cloud services, and applied machine learning, with a focus on reproducibility, evaluation, and real-world decision-making. Seeking a junior role to contribute to production data systems while continuing to grow as an engineer.\n\n\n\n\nCity University of New York â€“ School of Professional Studies\nMaster of Science, Data Science and Machine Learning â€” Jan 2026\nGPA: 4.0\nCity University of New York â€“ New York City College of Technology\nBachelor of Technology, Computer Information Systems â€” Jun 2024\nGPA: 3.78 | Deanâ€™s List (5Ã—) | National Honor Society\n\n\n\n\n\nAWS Certified Solutions Architect â€“ Associate\n\nAWS Certified AI Practitioner â€“ Generative AI\n\nGoogle Cybersecurity Certificate\n\nGoogle IT Support\n\n\n\n\n\n\n\nArlington, VA | Jun 2025 â€“ Sep 2025\n\nDesigned and evaluated secure, scalable AWS architectures, analyzing trade-offs across cost, performance, and operational complexity.\n\nBuilt end-to-end data analytics pipelines using Athena, Glue, SQL, and serverless components.\n\nDeveloped a fully automated sentiment analysis pipeline processing millions of text records, reducing feedback-to-action latency by approximately 5Ã— while maintaining full traceability.\n\nAutomated a previously 100% manual QA workflow, enabling analysts to focus on interpretation rather than processing.\n\nApplied NLP techniques and prompt-design strategies using foundation models via Amazon Bedrock.\n\nDesigned and deployed Amazon QuickSight dashboards to monitor sentiment trends and validate insights.\n\nPresented architectural designs and cost analyses to technical and non-technical stakeholders.\n\n\n\n\n\nRemote, NY | Jun 2024 â€“ Sep 2024\n\nDesigned system and data-flow architecture diagrams aligned with data governance and security requirements.\n\nIntegrated and tested APIs supporting decentralized identity workflows on the Ethereum network.\n\nEvaluated system behavior and edge cases to ensure correctness and reliability.\n\n\n\n\n\nRemote, NY | Feb 2022 â€“ Aug 2023\n\nDelivered 36 instructional sessions covering IT support, Linux, PowerShell, and scripting to 200+ learners.\n\nTracked learner engagement using Excel and Google Sheets, producing summary statistics and progress reports.\n\nUsed performance data to refine instruction, contributing to a 96% cohort graduation rate.\n\n\n\n\n\n\n\n\n\nBuilt a personal agentic job search assistant using FastAPI (Python) and OpenAI GPT models.\n\nImplemented a Retrieval-Augmented Generation (RAG) system using PostgreSQL with pgvector.\n\nApplied cosine similarity to match candidates to job postings, reducing application time by ~60%.\n\nConducted LLM evaluation using human-in-the-loop and LLM-as-judge techniques.\n\n\n\n\n\n\nLanguages & Programming\nPython (pandas, scikit-learn, PyTorch), R, SQL\nData & Analytics Tools\nExcel, PowerPoint, Google Sheets, Tableau, Power BI\nCloud & Data Platforms\nAWS (Athena, Glue, Bedrock, QuickSight), Databricks (familiarity)\nAI / ML Platforms\nOpenAI, Claude, Llama, Google GenAI\nTechniques & Methods\nETL, NLP, Classification, Regression, Ensemble Methods (CART), Forecasting (ARIMA), Anomaly Detection, Hypothesis Testing, EDA, PCA, Clustering\nDevelopment Environments\nJupyter, Colab, VS Code, Rstudio, Pycharm"
  },
  {
    "objectID": "resume.html#darwhin-gomez",
    "href": "resume.html#darwhin-gomez",
    "title": "Resume",
    "section": "",
    "text": "Data Engineer | Data Scientist\nNew York, NY\nðŸ“§ darwhin88@gmail.com\nðŸ”— https://linkedin.com/in/darwhin-gomez\nðŸ’» https://github.com/dw8888\n\n\n\nData engineer and data scientist with a Master of Science in Data Science and Machine Learning (GPA 4.0) and hands-on experience designing data pipelines, analytics workflows, and ML-enabled systems. Former AWS Solutions Architect Intern, where I built scalable, cloud-based analytics and NLP pipelines processing millions of records. Strong foundation in Python, SQL, cloud services, and applied machine learning, with a focus on reproducibility, evaluation, and real-world decision-making. Seeking a junior role to contribute to production data systems while continuing to grow as an engineer.\n\n\n\n\nCity University of New York â€“ School of Professional Studies\nMaster of Science, Data Science and Machine Learning â€” Jan 2026\nGPA: 4.0\nCity University of New York â€“ New York City College of Technology\nBachelor of Technology, Computer Information Systems â€” Jun 2024\nGPA: 3.78 | Deanâ€™s List (5Ã—) | National Honor Society\n\n\n\n\n\nAWS Certified Solutions Architect â€“ Associate\n\nAWS Certified AI Practitioner â€“ Generative AI\n\nGoogle Cybersecurity Certificate\n\nGoogle IT Support\n\n\n\n\n\n\n\nArlington, VA | Jun 2025 â€“ Sep 2025\n\nDesigned and evaluated secure, scalable AWS architectures, analyzing trade-offs across cost, performance, and operational complexity.\n\nBuilt end-to-end data analytics pipelines using Athena, Glue, SQL, and serverless components.\n\nDeveloped a fully automated sentiment analysis pipeline processing millions of text records, reducing feedback-to-action latency by approximately 5Ã— while maintaining full traceability.\n\nAutomated a previously 100% manual QA workflow, enabling analysts to focus on interpretation rather than processing.\n\nApplied NLP techniques and prompt-design strategies using foundation models via Amazon Bedrock.\n\nDesigned and deployed Amazon QuickSight dashboards to monitor sentiment trends and validate insights.\n\nPresented architectural designs and cost analyses to technical and non-technical stakeholders.\n\n\n\n\n\nRemote, NY | Jun 2024 â€“ Sep 2024\n\nDesigned system and data-flow architecture diagrams aligned with data governance and security requirements.\n\nIntegrated and tested APIs supporting decentralized identity workflows on the Ethereum network.\n\nEvaluated system behavior and edge cases to ensure correctness and reliability.\n\n\n\n\n\nRemote, NY | Feb 2022 â€“ Aug 2023\n\nDelivered 36 instructional sessions covering IT support, Linux, PowerShell, and scripting to 200+ learners.\n\nTracked learner engagement using Excel and Google Sheets, producing summary statistics and progress reports.\n\nUsed performance data to refine instruction, contributing to a 96% cohort graduation rate.\n\n\n\n\n\n\n\n\n\nBuilt a personal agentic job search assistant using FastAPI (Python) and OpenAI GPT models.\n\nImplemented a Retrieval-Augmented Generation (RAG) system using PostgreSQL with pgvector.\n\nApplied cosine similarity to match candidates to job postings, reducing application time by ~60%.\n\nConducted LLM evaluation using human-in-the-loop and LLM-as-judge techniques.\n\n\n\n\n\n\nLanguages & Programming\nPython (pandas, scikit-learn, PyTorch), R, SQL\nData & Analytics Tools\nExcel, PowerPoint, Google Sheets, Tableau, Power BI\nCloud & Data Platforms\nAWS (Athena, Glue, Bedrock, QuickSight), Databricks (familiarity)\nAI / ML Platforms\nOpenAI, Claude, Llama, Google GenAI\nTechniques & Methods\nETL, NLP, Classification, Regression, Ensemble Methods (CART), Forecasting (ARIMA), Anomaly Detection, Hypothesis Testing, EDA, PCA, Clustering\nDevelopment Environments\nJupyter, Colab, VS Code, Rstudio, Pycharm"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Darwhin Gomez",
    "section": "",
    "text": "I am a data professional with a strong foundation in data engineering, analytics, and machine learning. I recently completed a Master of Science in Data Science, where I worked extensively with real-world datasets, statistical modeling, and end-to-end data workflows.\nI have hands-on experience using Python, SQL, and R to build data pipelines, perform feature engineering, and develop machine learning models. My work spans academic projects and personal builds, with a focus on reproducibility, clear evaluation, and practical decision-making.\nI am currently seeking a junior data engineering or data-focused role where I can continue developing scalable data systems while contributing meaningfully to a team.\n\n\n\n\nLinkedIn: https://www.linkedin.com/in/darwhin-gomez\n\nGitHub: https://github.com/dw8888\n\nResume: Resume\n\n\n\n\n\nA selection of projects demonstrating data pipelines, modeling, and applied analytics.\n(See the Projects tab for full details.)\n\nFraud Detection Pipeline\nImbalanced classification workflow with feature engineering, model training, and precision-focused evaluation.\nAlfred â€“ AI Job Assistant (RAG)\nFastAPI-based system using PostgreSQL/pgvector and LLMs to generate tailored resumes and cover letters.\nBank Marketing Model Experiments\nComparative modeling using Decision Trees, Random Forests, AdaBoost, and SVMs with rigorous evaluation metrics."
  },
  {
    "objectID": "index.html#data-engineer-data-scientist",
    "href": "index.html#data-engineer-data-scientist",
    "title": "Darwhin Gomez",
    "section": "",
    "text": "I am a data professional with a strong foundation in data engineering, analytics, and machine learning. I recently completed a Master of Science in Data Science, where I worked extensively with real-world datasets, statistical modeling, and end-to-end data workflows.\nI have hands-on experience using Python, SQL, and R to build data pipelines, perform feature engineering, and develop machine learning models. My work spans academic projects and personal builds, with a focus on reproducibility, clear evaluation, and practical decision-making.\nI am currently seeking a junior data engineering or data-focused role where I can continue developing scalable data systems while contributing meaningfully to a team.\n\n\n\n\nLinkedIn: https://www.linkedin.com/in/darwhin-gomez\n\nGitHub: https://github.com/dw8888\n\nResume: Resume\n\n\n\n\n\nA selection of projects demonstrating data pipelines, modeling, and applied analytics.\n(See the Projects tab for full details.)\n\nFraud Detection Pipeline\nImbalanced classification workflow with feature engineering, model training, and precision-focused evaluation.\nAlfred â€“ AI Job Assistant (RAG)\nFastAPI-based system using PostgreSQL/pgvector and LLMs to generate tailored resumes and cover letters.\nBank Marketing Model Experiments\nComparative modeling using Decision Trees, Random Forests, AdaBoost, and SVMs with rigorous evaluation metrics."
  }
]